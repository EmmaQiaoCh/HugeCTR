# Please do not edit this file
import json
from collections import OrderedDict

import numpy as np
import matplotlib.pyplot as plt

FUSED_FULLY_CONNECTED_FORWARD_EVENTS = [
    'fused_fully_connected.fprop',
    'fused_fully_connected.fprop.cublasGemmEx',
    'fused_fully_connected.fprop.add_bias_and_re_kernel',
]

FUSED_FULLY_CONNECTED_BACKWARD_EVENTS = [
    'fused_fully_connected.bprop',
    'fused_fully_connected.bprop.initialize_array',
    'fused_fully_connected.bprop.reverse_add_bias_and_re_kernel',
    'fused_fully_connected.bprop.convert_array',
    'fused_fully_connected.bprop.cublasGemmEx_1',
    'fused_fully_connected.bprop.cublasGemmEx_2'
]

LOCALIZED_SLOT_SPARSE_EMBEDDING_ONE_HOT_FORWARD_EVENTS = [
    'localized_slot_sparse_embedding_one_hot.forward.mapping_and_fuse'
]


DRLM_EVENTS = {
    # interested event name
    'BottomMLP.fc1': {
        'same_name_events_occured_order_in_code_forward': 0,
        'same_name_events_occured_order_in_code_backward': 6,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    },
    'BottomMLP.fc2': {
        'same_name_events_occured_order_in_code_forward': 1,
        'same_name_events_occured_order_in_code_backward': 5,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    },
    'BottomMLP.fc3': {
        'same_name_events_occured_order_in_code_forward': 2,
        'same_name_events_occured_order_in_code_backward': 4,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    },
    'sparse_embedding1': {
        'same_name_events_occured_order_in_code_forward': 0,
        'same_name_events_occured_order_in_code_backward': 0,
        'forward_events': LOCALIZED_SLOT_SPARSE_EMBEDDING_ONE_HOT_FORWARD_EVENTS,
        'backward_events': []
    },
    'interaction1': {
        'same_name_events_occured_order_in_code_forward': 0,
        'same_name_events_occured_order_in_code_backward': 0,
        'forward_events': [],
        'backward_events': []
    },
    'TopMLP.fc4': {
        'same_name_events_occured_order_in_code_forward': 3,
        'same_name_events_occured_order_in_code_backward': 3,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    },
    'TopMLP.fc5': {
        'same_name_events_occured_order_in_code_forward': 4,
        'same_name_events_occured_order_in_code_backward': 2,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    },
    'TopMLP.fc6': {
        'same_name_events_occured_order_in_code_forward': 5,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'same_name_events_occured_order_in_code_backward': 1,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    },
    'TopMLP.fc7': {
        'same_name_events_occured_order_in_code_forward': 6,
        'forward_events': FUSED_FULLY_CONNECTED_FORWARD_EVENTS,
        'same_name_events_occured_order_in_code_backward': 0,
        'backward_events': FUSED_FULLY_CONNECTED_BACKWARD_EVENTS
    }
}


def generate_schedule(schedule, repeat_for_each_event=50, warmup_iterations=10, outfile='prof.schedule'):
    with open(outfile, 'w') as f:
        f.write(str(warmup_iterations))
        iteration = warmup_iterations + 1
        for layer in schedule:
            for interested_event in schedule[layer]:
                if interested_event in DRLM_EVENTS[layer]['forward_events']:
                    same_name_events_occured_order_in_code = DRLM_EVENTS[layer]['same_name_events_occured_order_in_code_forward']
                elif interested_event in DRLM_EVENTS[layer]['backward_events']:
                    same_name_events_occured_order_in_code = DRLM_EVENTS[layer]['same_name_events_occured_order_in_code_backward']
                else:
                    raise Exception("{} is not a registered event!".format(interested_event))
                for _ in range(repeat_for_each_event):
                    line = "\n{} {} {} {}".format(
                        interested_event,
                        iteration,
                        layer,
                        same_name_events_occured_order_in_code
                    )
                    f.write(line)
                    iteration += 1

def parse_result(prof_file='prof.json'):
    with open(prof_file, 'r') as f:
        jstring = f.read()
        prof = json.loads(jstring)
        timeline = prof['events']
        timeline.sort(key=lambda e: e["start_index"])
        result = {
            'iter_time_ms': sum(prof['iter_time_ms']) / len(prof['iter_time_ms']),
            'layers': split_by_layer_device_stream(timeline)
        }
    return result

def print_result(result):
    print(json.dumps(result, indent=2))


def split_by_layer_device_stream(timeline):
    # timeline is a array
    global_streams = []
    result = OrderedDict()
    for event in timeline:
        layer_name = event["layer_name"]
        if layer_name not in result.keys():
            result[layer_name] = OrderedDict()
        device_id = "device_" + str(event["device_id"])
        if device_id not in result[layer_name].keys():
            result[layer_name][device_id] = OrderedDict()
        if event["stream"] in global_streams:
            stream_id = "stream_" + str(global_streams.index(event["stream"]))
        else:
            stream_id = "stream_" + str(len(global_streams))
            global_streams.append(event["stream"])
        if stream_id not in result[layer_name][device_id].keys():
            result[layer_name][device_id][stream_id] = []
        new_event = OrderedDict()
        new_event["name"] = event["name"]
        new_event["start_index"] = event["start_index"]
        new_event["end_index"] = event["end_index"]

        measured_times_ms = reject_outliers(event["measured_times_ms"])
        new_event["avg_measured_times_ms"] = sum(measured_times_ms) / len(measured_times_ms)
        result[layer_name][device_id][stream_id].append(new_event)
    return result

def reject_outliers(data, m=2.):
    data = np.array(data)
    return data[abs(data - np.mean(data)) < m * np.std(data)].tolist()

def draw_barh(result):
    num_of_events = 0
    for l in result["layers"].keys():
        for d in result["layers"][l].keys():
            for s in result["layers"][l][d].keys():
                for _ in result["layers"][l][d][s]:
                    num_of_events += 1

    figure_width = 20
    figure_height = num_of_events * 0.9

    plt.figure(figsize=(figure_width, figure_height))
    plt.title('Profiling Result', fontsize=20)
    plt.xlabel(u'Time Cost in ms', fontsize=14)
    plt.ylabel(u'Events',fontsize=14, loc = 'top')

    width_val = 0.4 #若显示 n 个柱状图，则width_val的值需小于1/n ，否则柱形图会有重合

    y_labels = []
    x_events_data = []

    for l in result["layers"].keys():
        for d in result["layers"][l].keys():
            for s in result["layers"][l][d].keys():
                label = l + '_' + d + '_' + s + '_'
                for e in result["layers"][l][d][s]:
                    label = l + '_' + d + '_' + s + '_' + e["name"]
                    plt.barh(label, e["avg_measured_times_ms"])

    #plt.legend(loc=2)#图例展示位置，数字代表第几象限
    plt.show()#显示图像