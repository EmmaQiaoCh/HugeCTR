{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-population",
   "metadata": {},
   "source": [
    "# Notebook Usage\n",
    "\n",
    "Should you have any question, please contact Randy Wang(ruotongw@nvidia.com).\n",
    "\n",
    "## 1. Complie\n",
    "\n",
    "Add `-DENABLE_PROFILING=ON` when pass args to Cmake. And then do the normal `make` process.\n",
    "\n",
    "\n",
    "## 2. Config schedule\n",
    "\n",
    "Comment out anything you are not interested in `dlrm_perf_schedule` below. Just comment the event label line, don't comment out\n",
    "the `forward_events`, `backward_events` or `BottomMLP.fc1` line. You can check for all labels in the cpp code. And also you can add\n",
    "your own label and recompile it, then insert correspond label in `dlrm_perf_schedule`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-bahrain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 1000px; }</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "project_root = os.path.join(os.path.abspath(''), '..', '..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from tools.profiler import prepare_prof_dir, parse_result\n",
    "from tools.profiler.chart import timeline_chart, scaling_chart\n",
    "\n",
    "dlrm_perf_schedule = {\n",
    "    # interested event name\n",
    "    'BottomMLP.fc1': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc2': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc3': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'sparse_embedding1': {\n",
    "        'forward_events': [\n",
    "            'localized_slot_sparse_embedding_one_hot.forward',\n",
    "            'all2all_forward',\n",
    "            'inter_node_hier_a2a.fprop'\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'localized_slot_sparse_embedding_one_hot.backward',\n",
    "            'all2all_backward',\n",
    "            'inter_node_hier_a2a.bprop',\n",
    "            'localized_slot_sparse_embedding_one_hot.update_params'\n",
    "        ]\n",
    "    },\n",
    "    'interaction1': {\n",
    "        'forward_events': [\n",
    "            'interaction.fprop'\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'interaction.bprop'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc4': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc5': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc6': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc7': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc8': {\n",
    "        'forward_events': [\n",
    "            'fully_connected_layer_half.fprop',\n",
    "#            'fully_connected_layer_half.fprop.cublasGemmEx_1',\n",
    "#            'fully_connected_layer_half.fprop.cublasGemmEx_2'\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fully_connected_layer_half.bprop',\n",
    "#            'fully_connected_layer_half.bprop.cublasGemmEx_1',\n",
    "#            'fully_connected_layer_half.bprop.cublasGemmEx_2',\n",
    "#            'fully_connected_layer_half.bprop.cublasGemmEx_3'\n",
    "        ]\n",
    "    },\n",
    "    'Loss': {\n",
    "        'forward_events': [\n",
    "            'compute'\n",
    "        ]\n",
    "    },\n",
    "    'AllReduce_wgrads': {\n",
    "        'forward_events': [\n",
    "            'exchange_wgrad'\n",
    "        ]\n",
    "    },\n",
    "    'Update_Params': {\n",
    "        'forward_events': [\n",
    "            'update'\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-poison",
   "metadata": {},
   "source": [
    "## 3. Set config and generate the profiling dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define profiling_dir for this profiling session.\n",
    "# Specify the config file you want to use. Also other configs, like slurm related.\n",
    "working_dir = os.path.join('tools', 'profiler')\n",
    "# train configs\n",
    "config_name = '43008_8gpus'\n",
    "config_file = os.path.join('mlperf', 'configs', config_name + '.json')\n",
    "# slurm related\n",
    "nodes_num = 1\n",
    "container_name = 'hugectr-dlrm-profiling'\n",
    "image = 'gitlab-master.nvidia.com/dl/mlperf/optimized:recommendation.hugectr.2035814'\n",
    "mounts_str = '/raid:/raid,/lustre/fsw/mlperf/mlperft-dlrm/ruotongw/hugectr:/etc/workspace/home'\n",
    "account = 'mlperf'\n",
    "jobid = '1069007'\n",
    "# profiler related\n",
    "profiling_dir_name = 'dgxa100_{nodes_num}node_'.format(nodes_num=nodes_num) + config_name\n",
    "profiling_dir = os.path.join(working_dir, 'results', profiling_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-market",
   "metadata": {},
   "source": [
    "## 4. Generate the profiling dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create if profiling_dir non-exist. \n",
    "# Create a prof.schedule in profiling_dir. This file will instruct cpp profiler how to prof.\n",
    "# If you are not on cluster, you need to somehow upload the profiling dir to the corresponding\n",
    "# location on cluster. \n",
    "prepare_prof_dir(dlrm_perf_schedule, os.path.join(project_root, profiling_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-burst",
   "metadata": {},
   "source": [
    "## 5. Run the training\n",
    "\n",
    "### 5.a on the cluter, in the login node\n",
    "\n",
    "You may want to first\n",
    "```\n",
    "salloc -p luna -A {account} -N{nodes_num} bash\n",
    "```\n",
    "to apply for resources in advance. Remeber the jobid and fill in above.\n",
    "\n",
    "The hugectr will exit after the profiling is completed, usually only run for 1000 - 3000 iters, depends on how many\n",
    "interested events you defined in the dlrm_perf_schedule. The raw result will appear in profiling_dir as ${host_name}.prof.json.\n",
    "If you use multiple nodes, there will be several jsons appear. The result json is not human readable, so please use function below to parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '''\n",
    "    srun --mpi=pmix --ntasks=\"{nodes_num}\" --ntasks-per-node=1 --container-workdir /etc/workspace/home \\\\\n",
    "         --container-name=\"{container_name}\" --container-mounts=\"{mounts_str}\" --container-image={image} \\\\\n",
    "         --export=NCCL_LAUNCH_MODE=PARALLEL,PROFILING_DIR={profiling_dir} -A {account} --jobid={jobid}\\\\\n",
    "         numactl --interleave=all ./build/bin/huge_ctr --train {config_file}\n",
    "'''.format(mounts_str=mounts_str, nodes_num=nodes_num, image=image, container_name=container_name,\n",
    "           profiling_dir=profiling_dir, config_file=config_file, account=account, jobid=jobid)\n",
    "print(cmd)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-relief",
   "metadata": {},
   "source": [
    "### 5.b If you are already in the hugectr container, you have to run the trainning with env PROFILING_DIR, like:\n",
    "\n",
    "    export NCCL_LAUNCH_MODE=PARALLEL\n",
    "    export PROFILING_DIR={profiling_dir in the container}\n",
    "    numactl --interleave=all ./build/bin/huge_ctr --train {config_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-blink",
   "metadata": {},
   "source": [
    "## 5. Result\n",
    "\n",
    "The hugectr will exit after the profiling is completed, usually only run for 1000 - 3000 iters, depends on how many\n",
    "interested events you defined in the `dlrm_perf_schedule`. The raw result will appear in `profiling_dir` as\n",
    "`${host_name}.prof.json`. If you use multiple nodes, there will be several jsons appear. The result json is not\n",
    "human readable, so please use function below to parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-sleep",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the result into more human readable format.\n",
    "result = parse_result(os.path.join(project_root, profiling_dir))\n",
    "# print adn save the result\n",
    "with open(os.path.join(project_root, profiling_dir, profiling_dir_name + '.json'), 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "print(json.dumps(result, indent=2))\n",
    "# And you can do anything you like, for instance drawing all kinds of chart from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a timeline chart\n",
    "timeline_chart(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_dirs = [\n",
    "    os.path.join(project_root, 'tools', 'profiler', 'results', 'dgxa100_1node_43008_8gpus'),\n",
    "    os.path.join(project_root, 'tools', 'profiler', 'results', 'dgxa100_1node_55296_8gpus'),\n",
    "]\n",
    "results = []\n",
    "names = ['dgxa100_1node_43008_8gpus', 'dgxa100_1node_55296_8gpus']\n",
    "for prof_dir in profiling_dirs:\n",
    "    names.append(prof_dir)\n",
    "    results.append(parse_result(prof_dir))\n",
    "    \n",
    "# draw scaling chart\n",
    "scaling_chart(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
