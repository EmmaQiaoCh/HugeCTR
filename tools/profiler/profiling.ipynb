{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-population",
   "metadata": {},
   "source": [
    "# Notebook Usage\n",
    "\n",
    "1. Add `-DENABLE_PROFILING=ON` when pass args to Cmake. And then do the normal `make` process.\n",
    "\n",
    "2. Comment out anything you are not interested in `dlrm_perf_schedule` below. Just comment the event label line, don't comment out\n",
    "the `forward_events`, `backward_events` or `BottomMLP.fc1` line. You can check for all labels in the cpp code. And also you can add\n",
    "your own label and recompile it, then insert correspond label in `dlrm_perf_schedule`.\n",
    "\n",
    "3. Run the cell one by one and follow the instruction in each cell.\n",
    "\n",
    "4. Should you have any question, please contact Randy Wang(ruotongw@nvidia.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 1000px; }</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "\n",
    "from tools.profiler import generate_schedule, parse_result\n",
    "from tools.profiler.chart import timeline_chart, scaling_chart\n",
    "\n",
    "dlrm_perf_schedule = {\n",
    "    # interested event name\n",
    "    'BottomMLP.fc1': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc2': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc3': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'sparse_embedding1': {\n",
    "        'forward_events': [\n",
    "            'localized_slot_sparse_embedding_one_hot.forward.mapping_and_fuse'\n",
    "        ],\n",
    "        'backward_events': []\n",
    "    },\n",
    "    'interaction1': {\n",
    "        'forward_events': [],\n",
    "        'backward_events': [] \n",
    "    },\n",
    "    'TopMLP.fc4': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "    #        'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc5': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc6': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc7': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc8': {\n",
    "        'forward_events': [],\n",
    "        'backward_events': []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define profiling_dir for this profiling session. Specify the config file you want to use.\n",
    "\n",
    "working_dir = os.path.abspath('')\n",
    "profiling_dir = os.path.join(working_dir, 'test')\n",
    "config_file = os.path.join(working_dir, '../../mlperf/configs/55296_8gpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create if profiling_dir non-exist.\n",
    "os.makedirs(profiling_dir, exist_ok=True)\n",
    "# Copy config to profiling_dir, for backup\n",
    "copy(config_file, profiling_dir)\n",
    "# Create a prof.schedule in profiling_dir. This file will instruct cpp profiler how to prof. \n",
    "generate_schedule(dlrm_perf_schedule, profiling_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-trauma",
   "metadata": {},
   "source": [
    "## Run the training\n",
    "If you are not on cluster, you should upload the profiling_dir to corresponding location on cluster.\n",
    "Then you should run the training process like:\n",
    "```\n",
    "export PROFILING_DIR=${profiling dir defined above}\n",
    "numactl ./build/bin/hugectr --train ${PROFILING_DIR}/55926_8gpus.json\n",
    "```\n",
    "\n",
    "Or you can run from the login node like:\n",
    "```\n",
    "## DL params\n",
    "export CONTAINER_NAME=hugectr_inline_profiler\n",
    "export IMAGE=gitlab-master.nvidia.com/dl/mlperf/optimized:recommendation.hugectr.2035814\n",
    "export CONFIG=\"tools/profiler/test/55296_8gpus.json\"\n",
    "export MOUNTS=/raid:/raid,/lustre/fsw/mlperft-dlrm/ruotongw/hugectr:/etc/workspace/home\n",
    "\n",
    "# For Profiler\n",
    "export PROFILING_DIR=tools/profiler/test\n",
    "\n",
    "## NCCL WAR\n",
    "export NCCL_LAUNCH_MODE=PARALLEL\n",
    "\n",
    "# Setup container\n",
    "srun --ntasks=\"${SLURM_JOB_NUM_NODES}\" --container-image=\"${IMAGE}\" --container-name=\"${CONTAINER_NAME}\" true\n",
    "\n",
    "srun \\\n",
    "    --mpi=pmix \\\n",
    "    --ntasks=\"${SLURM_JOB_NUM_NODES}\" \\\n",
    "    --ntasks-per-node=1 \\\n",
    "    --container-workdir /etc/workspace/home \\\n",
    "    --container-name=\"${CONTAINER_NAME}\" \\\n",
    "    --container-mounts=\"${MOUNTS}\" \\\n",
    "    --export=NCCL_LAUNCH_MODE=PARALLEL,PROFILING_DIR=${PROFILING_DIR} \\\n",
    "    numactl --interleave=all /bin/bash -c \"./build/bin/huge_ctr --train ${CONFIG}\"\n",
    "```\n",
    "\n",
    "## Result\n",
    "\n",
    "The hugectr will exit after the profiling is completed, usually only run for 1000 - 3000 iters, depends on how many\n",
    "interested events you defined in the `dlrm_perf_schedule`. The raw result will appear in `profiling_dir` as\n",
    "`${host_name}.prof.json`. If you use multiple nodes, there will be several jsons appear. The result json is not\n",
    "human readable, so please use function below to parse it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-sleep",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the result into more human readable format.\n",
    "result = parse_result(profiling_dir)\n",
    "# print the result\n",
    "print(json.dumps(result, indent=2))\n",
    "# And you can do anything you like, for instance drawing all kinds of chart from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a timeline chart\n",
    "timeline_chart(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profiling_dirs = ['dgxA100-1node-batch55k', 'dgxA100-2node-batch55k', 'dgxA100-4node-batch55k']\n",
    "profiling_dirs = [profiling_dir]\n",
    "results = []\n",
    "names = []\n",
    "for prof_dir in profiling_dirs:\n",
    "    names.append(prof_dir)\n",
    "    results.append(parse_result(prof_dir))\n",
    "    \n",
    "# draw scaling chart\n",
    "scaling_chart(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
