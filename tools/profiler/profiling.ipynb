{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-population",
   "metadata": {},
   "source": [
    "# Inline Profiler\n",
    "\n",
    "Inline Profiler is designed to make better profiling experience than NsightSystem in some aspect and focusing on specific important modules, finally let developer know whether the optimization is really scaling.\n",
    "\n",
    "Currently NsightSystem has several disadvatanges when profiling HugeCTR:\n",
    "\n",
    "1. It introduce some overheads.\n",
    "2. There are many blanks in timeline view and too many kernels. It makes hard for developers to have a clear vision on things they are interested.\n",
    "\n",
    "So, we come up with this inline profiler, it:\n",
    "\n",
    "1. Try to reduce overhead as much as possible by running profiling on only 1 kernel per iteration with CudaEvent.\n",
    "2. Let user define what they are interested and try to provide a more clear vision on how things are optimized.\n",
    "3. Introduce zero overhead for the code in the formal release version.\n",
    "\n",
    "## Usage\n",
    "\n",
    "1. Add `-DENABLE_PROFILING=ON` when pass args to Cmake. And then do the normal `make` process.\n",
    "\n",
    "2. In `tools/profiler/schedule.py`, there defines all the optional events you may want to profile in each layer. You can just comment out some events you are not inerested in the `dlrm_perf_schedule`. If you want to add new event, please contact Randy Wang or Daniel Abel. It would be better to insert the profile macro `PROFILE_RECORD(label, stream, device_id)` by the profiler developer. We will try to meet developers' need and add necessary events.\n",
    "\n",
    "3. `cd HugeCTR_PROJECT_ROOT` and `python3 tools/profiler/schedule.py`. This will generate a `prof.schedule` file under the project root. It is used to instruct profiler to schedule profiling.\n",
    "\n",
    "4. Then just train the hugectr like normal, for example `NCCL_LAUNCH_MODE=PARALLEL ./build//bin/huge_ctr --train ./experiment/dlrm_fp16_16k.json`. The profiler will collect data during training and prof only 1 kernel per iteration and the program will terminate after profiling complete.\n",
    "\n",
    "5. A file named 'prof.json' will appear in the project root. It records the kernel execution order, stream, device, prof time, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 1000px; }</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "\n",
    "from tools.profiler import generate_schedule, parse_result, print_result, timeline_chart\n",
    "\n",
    "dlrm_perf_schedule = {\n",
    "    # interested event name\n",
    "    'BottomMLP.fc1': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc2': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc3': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'sparse_embedding1': {\n",
    "        'forward_events': [\n",
    "            'localized_slot_sparse_embedding_one_hot.forward.mapping_and_fuse'\n",
    "        ],\n",
    "        'backward_events': []\n",
    "    },\n",
    "    'interaction1': {\n",
    "        'forward_events': [],\n",
    "        'backward_events': [] \n",
    "    },\n",
    "    'TopMLP.fc4': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc5': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc6': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc7': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'            \n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc8': {\n",
    "        'forward_events': [],\n",
    "        'backward_events': []\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.abspath('')\n",
    "# some configs\n",
    "slurm_nodes = 4\n",
    "slurm_account = \"mlperft-dlrm\"\n",
    "container_image = \"gitlab-master.nvidia.com/dl/hugectr/hugectr:mlperf_multi-node_ib_nightly_ci.latest\"\n",
    "container_name = \"inline_profiler_hugectr\"\n",
    "container_mounts=\"/lustre/fsr:/raid,/lustre/fsw/mlperft-dlrm/ruotongw/hugectr:/etc/workspace/home\"\n",
    "config_file = os.path.join(working_dir, '../../mlperf/configs/55296_8gpus.json')\n",
    "\n",
    "profiling_dir = os.path.join(working_dir, 'test')\n",
    "#profiling_dir = os.path.join(working_dir, datetime.now().strftime(\"%Y-%d%m-%H-%M-%S\"))\n",
    "os.makedirs(profiling_dir, exist_ok=True)\n",
    "copy(config_file, profiling_dir)\n",
    "# generate the schedule\n",
    "generate_schedule(dlrm_perf_schedule, profiling_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training\n",
    "!srun \\\n",
    "    -A mlperft-dlrm \\\n",
    "    --container-image=\"gitlab-master.nvidia.com/dl/hugectr/hugectr:mlperf_multi-node_ib_nightly_ci.latest\" \\\n",
    "    --container-name=inline_profiler_hugectr \\\n",
    "    --container-workdir=/etc/workspace/home \\\n",
    "    --container-mounts=/lustre/fsr:/raid,/lustre/fsw/mlperft-dlrm/ruotongw/hugectr:/etc/workspace/home \\\n",
    "    --ntasks=2 \\\n",
    "    --ntasks-per-node 1 \\\n",
    "    --export=EDITOR,NCCL_LAUNCH_MODE=PARALLEL,PROFILING_DIR=tools/profiler/2021-0102-14-12-15 \\\n",
    "    build/bin/huge_ctr --train mlperf/configs/55296_8gpus.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-sleep",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = parse_result(profiling_dir)\n",
    "print_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a timeline chart\n",
    "timeline_chart(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#profiling_dirs = ['dgxA100-1node-batch55k', 'dgxA100-2node-batch55k', 'dgxA100-4node-batch55k']\n",
    "profiling_dirs = [profiling_dir]\n",
    "results = []\n",
    "names = []\n",
    "for prof_dir in profiling_dirs:\n",
    "    names.append(prof_dir)\n",
    "    results.append(parse_result(prof_dir))\n",
    "\n",
    "def scaling_chart(results, names):\n",
    "\n",
    "    bar_width = 0.2\n",
    "    x_label_font_size = 7\n",
    "    names_font_size = 9\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    iter_time_data = []\n",
    "    label_time_avg_data = []\n",
    "    label_time_max_data = []\n",
    "    \n",
    "    x_axis = np.array([i + 1 for i in range(len(results))])\n",
    "    for result in results:\n",
    "        iter_times = [host[\"avg_iter_time_ms\"] for host in result]\n",
    "        avg_iter_times = sum(iter_times) / len(iter_times)\n",
    "        iter_time_data.append(avg_iter_times)\n",
    "        \n",
    "        labels = {}\n",
    "        for host in result:\n",
    "            for device in host[\"timeline\"].keys():\n",
    "                for stream in host[\"timeline\"][device].keys():\n",
    "                    for event in host[\"timeline\"][device][stream]:\n",
    "                        if event['label'] not in labels.keys():\n",
    "                            labels[event['label']] = []\n",
    "                        labels[event['label']].append(event['avg_measured_time_ms'])\n",
    "\n",
    "        label_time_avg_data_this_result = []\n",
    "        label_time_max_data_this_result = []\n",
    "        for _, times in labels.items():\n",
    "            label_time_avg_data_this_result.append(sum(times) / len(times))\n",
    "            label_time_max_data_this_result.append(max(times))\n",
    "        label_time_avg_data.append(label_time_avg_data_this_result)\n",
    "        label_time_max_data.append(label_time_max_data_this_result)\n",
    "\n",
    "    iter_time_data = np.array(iter_time_data)\n",
    "    label_time_avg_data = np.array(label_time_avg_data)\n",
    "    label_time_max_data = np.array(label_time_max_data)\n",
    "    \n",
    "    plt.bar(x_axis, iter_time_data, bar_width, align='edge')\n",
    "    accumulate_label_time_avg_data = np.zeros_like(label_time_avg_data[:, 0])\n",
    "    accumulate_label_time_max_data = np.zeros_like(label_time_max_data[:, 0])\n",
    "    \n",
    "    for i in range(label_time_avg_data.shape[1]):\n",
    "        plt.bar(x_axis + bar_width, label_time_avg_data[:, i], bar_width,\n",
    "                bottom=accumulate_label_time_avg_data, align='edge')\n",
    "        plt.bar(x_axis + 2 * bar_width, label_time_max_data[:, i], bar_width,\n",
    "                bottom=accumulate_label_time_max_data, align='edge')\n",
    "        accumulate_label_time_avg_data += label_time_avg_data[:, i]\n",
    "        accumulate_label_time_max_data += label_time_max_data[:, i]\n",
    "        \n",
    "    x_ticks = np.concatenate((x_axis + bar_width / 2, x_axis + bar_width + bar_width / 2,\n",
    "                             x_axis + 2 * bar_width + bar_width / 2))\n",
    "    x_labels = ['Whole iteration', 'Avg_mesured_ms', 'Max_measured_ms'] * len(results)\n",
    "    print(x_ticks)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticklabels(x_labels, fontdict={ 'fontsize' : x_label_font_size })\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        annot = ax.annotate(names[i], xy=(i + 1 + 3 * bar_width / 2, 0), xytext=(0, -30), \n",
    "                            textcoords=\"offset points\", fontsize=names_font_size, ha='center', va='center')\n",
    "\n",
    "    ax.grid(True)\n",
    "    fig.set_size_inches(8, 10)\n",
    "    plt.show()\n",
    "    \n",
    "scaling_chart(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
