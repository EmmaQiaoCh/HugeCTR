{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "liquid-population",
   "metadata": {},
   "source": [
    "# Notebook Usage\n",
    "\n",
    "Should you have any question, please contact Randy Wang(ruotongw@nvidia.com).\n",
    "\n",
    "## 1. Insert Macro and Complie\n",
    "\n",
    "a. You can insert macro `PROFILE_RECORD(xxx)` to CPP code to instruct profiler to profile this interval. There are some\n",
    "macro inserted already, please have a check if you are looking for example. Remeber to insert a pair of labels `xxx.start`\n",
    "and `xxx.stop`.\n",
    "\n",
    "b. Add `-DENABLE_PROFILING=ON` when pass args to Cmake. And then do the normal `make` process.\n",
    "\n",
    "\n",
    "## 2. Config schedule\n",
    "\n",
    "Below `dlrm_interesed_events` shows the stucture of DLRM model. Comment out anything you are not interested in\n",
    "`dlrm_interesed_events` below. Just comment the event label line, don't comment out\n",
    "the `forward_events`, `backward_events` or `BottomMLP.fc1` line. You can check for all labels in the cpp code. If you\n",
    "inserted some custom macro in step 1, make sure you add correspond label in `dlrm_interesed_events`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-bahrain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 1000px; }</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "import json\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "project_root = os.path.join(os.path.abspath(''), '..', '..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from tools.profiler import parse_result, gen_prof_config\n",
    "from tools.profiler.chart import timeline_chart, scaling_chart\n",
    "\n",
    "dlrm_interesed_events = {\n",
    "    # interested event name\n",
    "    'BottomMLP.fc1': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc2': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'BottomMLP.fc3': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'sparse_embedding1': {\n",
    "        'forward_events': [\n",
    "            'localized_slot_sparse_embedding_one_hot.forward',\n",
    "            'all2all_forward',\n",
    "            'inter_node_hier_a2a.fprop'\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'localized_slot_sparse_embedding_one_hot.backward',\n",
    "            'all2all_backward',\n",
    "            'inter_node_hier_a2a.bprop',\n",
    "            'localized_slot_sparse_embedding_one_hot.update_params'\n",
    "        ]\n",
    "    },\n",
    "    'interaction1': {\n",
    "        'forward_events': [\n",
    "            'interaction.fprop'\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'interaction.bprop'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc4': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc5': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc6': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc7': {\n",
    "        'forward_events': [\n",
    "            'fused_relu_bias_fully_connected.fprop',\n",
    "#            'fused_relu_bias_fully_connected.fprop.cublasLtMatmul',\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fused_relu_bias_fully_connected.bprop',\n",
    "#            'fused_relu_bias_fully_connected.bprop.initialize_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.reverse_add_bias_and_re_kernel',\n",
    "#            'fused_relu_bias_fully_connected.bprop.convert_array',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_1',\n",
    "#            'fused_relu_bias_fully_connected.bprop.cublasGemmEx_2'\n",
    "        ]\n",
    "    },\n",
    "    'TopMLP.fc8': {\n",
    "        'forward_events': [\n",
    "            'fully_connected_layer_half.fprop',\n",
    "#            'fully_connected_layer_half.fprop.cublasGemmEx_1',\n",
    "#            'fully_connected_layer_half.fprop.cublasGemmEx_2'\n",
    "        ],\n",
    "        'backward_events': [\n",
    "            'fully_connected_layer_half.bprop',\n",
    "#            'fully_connected_layer_half.bprop.cublasGemmEx_1',\n",
    "#            'fully_connected_layer_half.bprop.cublasGemmEx_2',\n",
    "#            'fully_connected_layer_half.bprop.cublasGemmEx_3'\n",
    "        ]\n",
    "    },\n",
    "    'Loss': {\n",
    "        'forward_events': [\n",
    "            'compute'\n",
    "        ]\n",
    "    },\n",
    "    'AllReduce_wgrads': {\n",
    "        'forward_events': [\n",
    "            'exchange_wgrad'\n",
    "        ]\n",
    "    },\n",
    "    'Update_Params': {\n",
    "        'forward_events': [\n",
    "            'update'\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-poison",
   "metadata": {},
   "source": [
    "## 3. Set related variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define profiling_dir for this profiling session.\n",
    "# Specify the config file you want to use. Also other configs, like slurm related.\n",
    "working_dir = os.path.join('tools', 'profiler')\n",
    "# profiler related\n",
    "profiling_dir_name = 'test'\n",
    "profiling_dir = os.path.join(working_dir, 'results', profiling_dir_name)\n",
    "\n",
    "# train configs\n",
    "config_file = os.path.join('mlperf', 'configs', '55296_8gpus.json')\n",
    "# slurm related\n",
    "nodes_num = 1\n",
    "container_name = 'hugectr-dlrm-profiling'\n",
    "image = 'gitlab-master.nvidia.com/dl/mlperf/optimized:recommendation.hugectr.2035814'\n",
    "mounts_str = '/raid:/raid,/lustre/fsw/mlperf/mlperft-dlrm/ruotongw/hugectr:/etc/workspace/home'\n",
    "account = 'mlperf'\n",
    "jobid = '1069007'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-market",
   "metadata": {},
   "source": [
    "## 4. Generate the profiling dir (optional)\n",
    "\n",
    "By default, profiler will prof every label inserted in CPP code, it usually cost 3min - 5min to finish the profiling,\n",
    "depends on how many labels inserted. And the `parse_result` will use `dlrm_interesed_events` to filer the result. So\n",
    "don't worry too many labels in CPP code will ruin the result. \n",
    "\n",
    "But, if you truly want to profile anything you care about, and to shorten the profiling time maybe, you can use below\n",
    "function to generate profiling dir and a `prof.events` file in it. It will instruct profiler to strictly only profile\n",
    "what you list in `dlrm_interesed_events`. And you need to somehow upload the profiling dir to the corresponding\n",
    "location on cluster or container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_prof_config(os.path.join(project_root, profiling_dir), interested_events=dlrm_interesed_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-burst",
   "metadata": {},
   "source": [
    "## 5. Run the training\n",
    "\n",
    "### 5.a on the cluter, in the login node\n",
    "\n",
    "You may want to first\n",
    "```\n",
    "salloc -p luna -A {account} -N{nodes_num} bash\n",
    "```\n",
    "to apply for resources in advance. Remeber the jobid and fill in above.\n",
    "\n",
    "The hugectr will exit after the profiling is completed, usually only run for 1000 - 3000 iters, depends on how many\n",
    "interested events you defined in the dlrm_perf_schedule. The raw result will appear in profiling_dir as ${host_name}.prof.json.\n",
    "If you use multiple nodes, there will be several jsons appear. The result json is not human readable, so please use function\n",
    "below to parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '''\n",
    "    srun --mpi=pmix --ntasks=\"{nodes_num}\" --ntasks-per-node=1 --container-workdir /etc/workspace/home \\\\\n",
    "         --container-name=\"{container_name}\" --container-mounts=\"{mounts_str}\" --container-image={image} \\\\\n",
    "         --export=NCCL_LAUNCH_MODE=PARALLEL,PROFILING_DIR={profiling_dir} -A {account} --jobid={jobid}\\\\\n",
    "         numactl --interleave=all ./build/bin/huge_ctr --train {config_file}\n",
    "'''.format(mounts_str=mounts_str, nodes_num=nodes_num, image=image, container_name=container_name,\n",
    "           profiling_dir=profiling_dir, config_file=config_file, account=account, jobid=jobid)\n",
    "print(cmd)\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-relief",
   "metadata": {},
   "source": [
    "### 5.b If you are already in the hugectr container, you have to run the trainning with env PROFILING_DIR, like:\n",
    "\n",
    "    export NCCL_LAUNCH_MODE=PARALLEL\n",
    "    export PROFILING_DIR={profiling_dir in the container}\n",
    "    numactl --interleave=all ./build/bin/huge_ctr --train {config_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-blink",
   "metadata": {},
   "source": [
    "## 6. Result\n",
    "\n",
    "The hugectr will exit after the profiling is completed. The raw result will appear in `profiling_dir` as\n",
    "`${host_name}.prof.json`. If you use multiple nodes, there will be several jsons appear. The result json is not\n",
    "human readable, so please use function below to parse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-sleep",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the result into more human readable format.\n",
    "result = parse_result(os.path.join(project_root, profiling_dir), dlrm_interesed_events)\n",
    "# print and save the result\n",
    "with open(os.path.join(project_root, profiling_dir, 'test' + '.json'), 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "print(json.dumps(result, indent=2))\n",
    "# And you can do anything you like, for instance drawing all kinds of chart from the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a timeline chart\n",
    "timeline_chart(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_dirs = [\n",
    "    os.path.join(project_root, 'tools', 'profiler', 'results', 'dgxa100_1node_43008_8gpus'),\n",
    "    os.path.join(project_root, 'tools', 'profiler', 'results', 'dgxa100_1node_55296_8gpus'),\n",
    "]\n",
    "results = []\n",
    "names = ['dgxa100_1node_43008_8gpus', 'dgxa100_1node_55296_8gpus']\n",
    "for prof_dir in profiling_dirs:\n",
    "    results.append(parse_result(prof_dir))\n",
    "    \n",
    "# draw scaling chart\n",
    "scaling_chart(results, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
